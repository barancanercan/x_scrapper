# ğŸ¦ X (Twitter) Scraper - Profesyonel Tweet Toplama AracÄ±

<div align="center">

![X Scraper](https://img.shields.io/badge/X-Scraper-1DA1F2?style=for-the-badge&logo=twitter&logoColor=white)
![Python](https://img.shields.io/badge/Python-3.8+-3776AB?style=for-the-badge&logo=python&logoColor=white)
![Selenium](https://img.shields.io/badge/Selenium-43B02A?style=for-the-badge&logo=selenium&logoColor=white)
![Gradio](https://img.shields.io/badge/Gradio-FF6B6B?style=for-the-badge&logo=gradio&logoColor=white)

**X (Twitter) hesabÄ±nÄ±zdaki tweet'leri otomatik olarak toplayÄ±p analiz eden gÃ¼Ã§lÃ¼ scraper aracÄ±**

[ğŸš€ HÄ±zlÄ± BaÅŸlangÄ±Ã§](#-hÄ±zlÄ±-baÅŸlangÄ±Ã§) â€¢ [ğŸ“– KullanÄ±m KÄ±lavuzu](#-kullanÄ±m-kÄ±lavuzu) â€¢ [ğŸ”§ Kurulum](#-detaylÄ±-kurulum) â€¢ [â“ Sorun Giderme](#-sorun-giderme)

</div>

---

## ğŸ“‹ Ä°Ã§indekiler

- [ğŸŒŸ Ã–zellikler](#-Ã¶zellikler)
- [ğŸš€ HÄ±zlÄ± BaÅŸlangÄ±Ã§](#-hÄ±zlÄ±-baÅŸlangÄ±Ã§)
- [ğŸ“¦ Sistem Gereksinimleri](#-sistem-gereksinimleri)
- [ğŸ”§ DetaylÄ± Kurulum](#-detaylÄ±-kurulum)
- [ğŸ“– KullanÄ±m KÄ±lavuzu](#-kullanÄ±m-kÄ±lavuzu)
- [ğŸ“Š Ã‡Ä±ktÄ± FormatlarÄ±](#-Ã§Ä±ktÄ±-formatlarÄ±)
- [âš™ï¸ YapÄ±landÄ±rma](#ï¸-yapÄ±landÄ±rma)
- [ğŸ”’ GÃ¼venlik](#-gÃ¼venlik)
- [â“ Sorun Giderme](#-sorun-giderme)
- [ğŸ¤ KatkÄ±da Bulunma](#-katkÄ±da-bulunma)
- [ğŸ“„ Lisans](#-lisans)

---

## ğŸŒŸ Ã–zellikler

### ğŸ¯ **Temel Ã–zellikler**
- âœ… **GerÃ§ek X Scraping**: Ana sayfa timeline'Ä±ndan gerÃ§ek tweet'leri toplar
- âœ… **Otomatik GiriÅŸ**: X hesabÄ±nÄ±za gÃ¼venli giriÅŸ yapar
- âœ… **EtkileÅŸim Verileri**: BeÄŸeni, retweet, yanÄ±t sayÄ±larÄ±nÄ± toplar
- âœ… **CSV Export**: Google Sheets'e aktarÄ±labilir format
- âœ… **Web ArayÃ¼zÃ¼**: KullanÄ±cÄ± dostu Gradio interface
- âœ… **Otomatik Driver**: ChromeDriver otomatik yÃ¶netimi

### ğŸ› ï¸ **Teknik Ã–zellikler**
- ğŸ”„ **Anti-Detection**: Bot algÄ±lama karÅŸÄ±tÄ± Ã¶nlemler
- ğŸ“Š **Real-time Stats**: AnlÄ±k istatistik takibi
- ğŸ›ï¸ **Ayarlanabilir**: Tweet sayÄ±sÄ± ve hÄ±z kontrolÃ¼
- ğŸ’¾ **Veri YÃ¶netimi**: Otomatik dosya isimlendirme
- ğŸ–¥ï¸ **Cross-Platform**: Ubuntu/Linux desteÄŸi
- ğŸ”’ **GÃ¼venli**: Yerel veri iÅŸleme, harici sunucu yok

### ğŸ“ˆ **Toplanan Veriler**
| Veri TÃ¼rÃ¼ | AÃ§Ä±klama | Format |
|------------|----------|---------|
| Tweet Metni | Tam tweet iÃ§eriÄŸi | String (300 karakter) |
| Yazar | Tweet sahibinin adÄ± | String |
| BeÄŸeni SayÄ±sÄ± | Like count | Integer |
| Retweet SayÄ±sÄ± | RT count | Integer |
| YanÄ±t SayÄ±sÄ± | Reply count | Integer |
| Tweet URL'si | Direkt tweet linki | URL |
| Zaman DamgasÄ± | Toplama zamanÄ± | DateTime |

---

## ğŸš€ HÄ±zlÄ± BaÅŸlangÄ±Ã§

### âš¡ 30 Saniyede BaÅŸlatma

```bash
# 1. KlasÃ¶re git
cd ~/Desktop/x_scrapper

# 2. Kurulum (ilk kez)
./setup_x_scraper.sh

# 3. BaÅŸlat
./start_x_scraper.sh
```

### ğŸŒ Web ArayÃ¼zÃ¼
Uygulama baÅŸladÄ±ktan sonra tarayÄ±cÄ±nÄ±zda otomatik aÃ§Ä±lacak:
```
http://127.0.0.1:7864
```

---

## ğŸ“¦ Sistem Gereksinimleri

### ğŸ–¥ï¸ **Ä°ÅŸletim Sistemi**
- Ubuntu 18.04+ (Ã¶nerilen: 20.04 veya 22.04)
- Debian 10+
- Linux Mint 19+

### ğŸ **Python**
- Python 3.8 veya Ã¼zeri
- pip paket yÃ¶neticisi
- venv modÃ¼lÃ¼

### ğŸŒ **TarayÄ±cÄ±**
- Google Chrome 90+ veya Chromium
- Otomatik gÃ¼ncellemeler aktif Ã¶nerilir

### ğŸ’¾ **DonanÄ±m**
| BileÅŸen | Minimum | Ã–nerilen |
|---------|---------|----------|
| RAM | 2 GB | 4 GB+ |
| Disk | 1 GB boÅŸ alan | 5 GB+ |
| Ä°ÅŸlemci | 2 Ã§ekirdek | 4 Ã§ekirdek+ |
| Ä°nternet | 1 Mbps | 5 Mbps+ |

---

## ğŸ”§ DetaylÄ± Kurulum

### 1ï¸âƒ£ **Sistem HazÄ±rlÄ±ÄŸÄ±**

```bash
# Sistem gÃ¼ncellemesi
sudo apt update && sudo apt upgrade -y

# Python ve temel araÃ§lar
sudo apt install python3 python3-pip python3-venv curl wget -y

# Chrome/Chromium kurulumu
sudo apt install chromium-browser -y
# VEYA Google Chrome:
# wget -q -O - https://dl.google.com/linux/linux_signing_key.pub | sudo apt-key add -
# sudo sh -c 'echo "deb [arch=amd64] http://dl.google.com/linux/chrome/deb/ stable main" >> /etc/apt/sources.list.d/google-chrome.list'
# sudo apt update && sudo apt install google-chrome-stable -y
```

### 2ï¸âƒ£ **Proje Kurulumu**

```bash
# Proje klasÃ¶rÃ¼nÃ¼ oluÅŸtur
mkdir -p ~/Desktop/x_scrapper
cd ~/Desktop/x_scrapper

# DosyalarÄ± indir/kopyala (bu README ile birlikte gelen dosyalar)
# x_scraper.py, setup_x_scraper.sh, start_x_scraper.sh

# Scriptleri Ã§alÄ±ÅŸtÄ±rÄ±labilir yap
chmod +x setup_x_scraper.sh start_x_scraper.sh

# Python sanal ortamÄ± ve baÄŸÄ±mlÄ±lÄ±klarÄ± kur
./setup_x_scraper.sh
```

### 3ï¸âƒ£ **Ä°lk Ã‡alÄ±ÅŸtÄ±rma**

```bash
# X Scraper'Ä± baÅŸlat
./start_x_scraper.sh
```

### 4ï¸âƒ£ **Kurulum DoÄŸrulama**

AÅŸaÄŸÄ±daki adÄ±mlarÄ± takip ederek kurulumun baÅŸarÄ±lÄ± olduÄŸunu doÄŸrulayÄ±n:

1. âœ… Terminal'de "ğŸš€ X Scraper arayÃ¼zÃ¼ aÃ§Ä±lÄ±yor..." mesajÄ± gÃ¶rÃ¼nÃ¼r
2. âœ… TarayÄ±cÄ±da http://127.0.0.1:7864 adresi aÃ§Ä±lÄ±r  
3. âœ… "ğŸ¦ X (Twitter) Scraper" baÅŸlÄ±ÄŸÄ± gÃ¶rÃ¼nÃ¼r
4. âœ… "ğŸš€ TarayÄ±cÄ± HazÄ±rla" butonu Ã§alÄ±ÅŸÄ±r

---

## ğŸ“– KullanÄ±m KÄ±lavuzu

### ğŸ”° **Temel KullanÄ±m**

#### **AdÄ±m 1: TarayÄ±cÄ± HazÄ±rlÄ±ÄŸÄ±**
1. Web arayÃ¼zÃ¼nde **"ğŸš€ TarayÄ±cÄ± HazÄ±rla"** butonuna tÄ±klayÄ±n
2. ChromeDriver otomatik olarak indirilip kurulacak
3. **"âœ… Chrome driver otomatik olarak kuruldu ve hazÄ±r!"** mesajÄ±nÄ± bekleyin

#### **AdÄ±m 2: X HesabÄ±na GiriÅŸ**
1. **X KullanÄ±cÄ± AdÄ±** alanÄ±na hesap adÄ±nÄ±zÄ± girin (@ iÅŸareti olmadan)
   ```
   Ã–rnek: barancanercan (âŒ @barancanercan deÄŸil)
   ```
2. **X Åifre** alanÄ±na hesap ÅŸifrenizi girin
3. **"ğŸ” X'e GiriÅŸ Yap"** butonuna tÄ±klayÄ±n
4. GiriÅŸ iÅŸlemi 10-15 saniye sÃ¼rebilir

#### **AdÄ±m 3: Tweet Toplama**
1. **Tweet SayÄ±sÄ±** belirleyin (5-100 arasÄ± Ã¶nerilir)
   - Ä°lk kullanÄ±m: 10-20 tweet
   - Deneyimli kullanÄ±m: 50-100 tweet
2. **"ğŸš€ Tweet Topla"** butonuna tÄ±klayÄ±n
3. Ä°ÅŸlem sÃ¼resi: ~30 saniye (20 tweet iÃ§in)

#### **AdÄ±m 4: Veri Kaydetme**
1. Tweet toplama tamamlandÄ±ÄŸÄ±nda **"ğŸ’¾ CSV Kaydet"** tÄ±klayÄ±n
2. Dosya `x_tweets_YYYYMMDD_HHMMSS.csv` formatÄ±nda kaydedilir
3. Google Sheets'e import edebilirsiniz

### ğŸ›ï¸ **GeliÅŸmiÅŸ KullanÄ±m**

#### **Tweet SayÄ±sÄ± Optimizasyonu**
| Tweet SayÄ±sÄ± | SÃ¼re | Ram KullanÄ±mÄ± | Ã–nerilen Durum |
|---------------|------|---------------|----------------|
| 5-10 | ~15 sn | DÃ¼ÅŸÃ¼k | Test/Deneme |
| 20-30 | ~45 sn | Orta | GÃ¼nlÃ¼k kullanÄ±m |
| 50-70 | ~2 dk | YÃ¼ksek | HaftalÄ±k analiz |
| 80-100 | ~3 dk | Ã‡ok YÃ¼ksek | AylÄ±k rapor |

#### **HÄ±z ve Kalite AyarlarÄ±**
```python
# GeliÅŸmiÅŸ kullanÄ±cÄ±lar iÃ§in x_scraper.py iÃ§inde deÄŸiÅŸtirilebilir:

# Scroll bekleme sÃ¼resi (saniye)
time.sleep(3)  # VarsayÄ±lan: 3sn, HÄ±zlÄ±: 2sn, GÃ¼venli: 5sn

# Maksimum scroll sayÄ±sÄ±
max_scrolls = 15  # VarsayÄ±lan: 15, HÄ±zlÄ±: 10, KapsamlÄ±: 25

# Sayfa yÃ¼kleme beklemesi
time.sleep(5)  # VarsayÄ±lan: 5sn, HÄ±zlÄ±: 3sn, GÃ¼venli: 8sn
```

### ğŸ”„ **Otomatik KullanÄ±m SenaryolarÄ±**

#### **GÃ¼nlÃ¼k Tweet Toplama**
```bash
# Cron job ile gÃ¼nlÃ¼k otomatik toplama
# crontab -e
0 9 * * * cd ~/Desktop/x_scrapper && ./daily_scrape.sh
```

#### **Toplu Analiz**
```bash
# Birden fazla CSV'yi birleÅŸtirme
cat x_tweets_*.csv > combined_tweets.csv
```

---

## ğŸ“Š Ã‡Ä±ktÄ± FormatlarÄ±

### ğŸ“„ **CSV FormatÄ±**
```csv
zaman,tweet,yazar,beÄŸeni,retweet,yanÄ±t,url
2025-07-29 14:30,Bu harika bir tweet!,Kullanici123,150,25,8,https://x.com/status/123456789
2025-07-29 14:31,Python Ã¶ÄŸreniyorum ğŸ,TechLover,89,12,3,https://x.com/status/123456790
```

### ğŸ“ˆ **JSON FormatÄ±** (Ä°steÄŸe baÄŸlÄ±)
```json
{
  "tweets": [
    {
      "zaman": "2025-07-29 14:30",
      "tweet": "Bu harika bir tweet!",
      "yazar": "Kullanici123",
      "beÄŸeni": 150,
      "retweet": 25,
      "yanÄ±t": 8,
      "url": "https://x.com/status/123456789"
    }
  ],
  "istatistikler": {
    "toplam_tweet": 20,
    "toplam_beÄŸeni": 2840,
    "ortalama_beÄŸeni": 142
  }
}
```

### ğŸ“Š **Google Sheets Ä°mport**
1. **Google Sheets** aÃ§Ä±n
2. **File â†’ Import â†’ Upload** seÃ§in
3. CSV dosyasÄ±nÄ± sÃ¼rÃ¼kleyin
4. **Separator type: Comma** seÃ§in
5. **Import data** tÄ±klayÄ±n

### ğŸ“ˆ **Excel Analizi**
```excel
=AVERAGE(D:D)     // Ortalama beÄŸeni
=SUM(E:E)         // Toplam retweet  
=MAX(F:F)         // En Ã§ok yanÄ±t
=COUNTIF(C:C,"*Tech*")  // "Tech" iÃ§eren yazarlar
```

---

## âš™ï¸ YapÄ±landÄ±rma

### ğŸ”§ **Temel Ayarlar**

#### **Port DeÄŸiÅŸtirme**
```python
# x_scraper.py dosyasÄ±nÄ±n en altÄ±nda
app.launch(server_name="127.0.0.1", server_port=7864, inbrowser=True)
# 7864 yerine istediÄŸiniz portu yazÄ±n (Ã¶rn: 8080)
```

#### **TarayÄ±cÄ± Modu**
```python
# Headless mod (arka planda Ã§alÄ±ÅŸtÄ±rma)
options.add_argument("--headless")

# Debug mod (geliÅŸtirici araÃ§larÄ±)
options.add_argument("--auto-open-devtools-for-tabs")
```

### ğŸ›¡ï¸ **GÃ¼venlik AyarlarÄ±**

#### **Rate Limiting** (HÄ±z SÄ±nÄ±rlama)
```python
# Daha gÃ¼venli scraping iÃ§in bekleme sÃ¼relerini artÄ±rÄ±n
time.sleep(5)  # Sayfa geÃ§iÅŸleri arasÄ±
time.sleep(3)  # Scroll'lar arasÄ±
```

#### **User Agent DeÄŸiÅŸtirme**
```python
options.add_argument("--user-agent=Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36")
```

### ğŸ“ **Dosya AyarlarÄ±**

#### **Ã‡Ä±ktÄ± Dizini**
```python
# FarklÄ± klasÃ¶re kaydetme
csv_file = Path("outputs/tweets/x_tweets_{timestamp}.csv")
```

#### **Dosya FormatÄ±**
```python
# Dosya adÄ± formatÄ±nÄ± deÄŸiÅŸtirme
timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
csv_file = Path(f"tweets_{username}_{timestamp}.csv")
```

---

## ğŸ”’ GÃ¼venlik

### ğŸ›¡ï¸ **Veri GÃ¼venliÄŸi**

#### **Yerel Veri Ä°ÅŸleme**
- âœ… TÃ¼m veriler yerel bilgisayarÄ±nÄ±zda kalÄ±r
- âœ… HiÃ§bir veri harici sunucuya gÃ¶nderilmez
- âœ… Ä°nternet sadece X'e baÄŸlanmak iÃ§in kullanÄ±lÄ±r

#### **Hesap GÃ¼venliÄŸi**
- âš ï¸ **Ã–nemli**: Sadece kendi hesabÄ±nÄ±zÄ± kullanÄ±n
- âš ï¸ **2FA**: Ä°ki faktÃ¶rlÃ¼ kimlik doÄŸrulama etkinse devre dÄ±ÅŸÄ± bÄ±rakÄ±n
- âš ï¸ **Åifre**: GÃ¼Ã§lÃ¼ ÅŸifre kullanÄ±n, paylaÅŸmayÄ±n

#### **Bot AlgÄ±lama Ã–nlemleri**
```python
# Mevcut anti-detection Ã¶zellikleri:
- User-Agent maskeleme
- WebDriver Ã¶zelliklerini gizleme  
- Ä°nsan benzeri davranÄ±ÅŸ (scroll, beklemeler)
- Rastgele timing deÄŸiÅŸiklikleri
```

### ğŸ” **Gizlilik Ã–nlemleri**

#### **Credential YÃ¶netimi**
```bash
# Åifrelerinizi script'te saklamayÄ±n!
# Her seferinde manuel girin veya environment variable kullanÄ±n

export X_USERNAME="kullanici_adi"
export X_PASSWORD="sifre"
```

#### **Log Temizleme**
```bash
# Hassas loglarÄ± temizleme
rm -f ~/.cache/selenium/
rm -f /tmp/chrome*
```

---

## â“ Sorun Giderme

### ğŸ”§ **YaygÄ±n Sorunlar ve Ã‡Ã¶zÃ¼mleri**

#### **1. ChromeDriver UyumsuzluÄŸu**
```
âŒ Hata: "This version of ChromeDriver only supports Chrome version X"
```
**Ã‡Ã¶zÃ¼m:**
```bash
# Chrome'u gÃ¼ncelleyin
sudo apt update && sudo apt upgrade google-chrome-stable

# Veya scraper'Ä± yeniden baÅŸlatÄ±n (otomatik gÃ¼nceller)
./start_x_scraper.sh
```

#### **2. X GiriÅŸ BaÅŸarÄ±sÄ±z**
```
âŒ Hata: "GiriÅŸ doÄŸrulanamadÄ±"
```
**Ã‡Ã¶zÃ¼mler:**
```bash
# a) KullanÄ±cÄ± adÄ±nda @ iÅŸareti olmasÄ±n
âŒ @kullanici_adi
âœ… kullanici_adi

# b) 2FA kapalÄ± olmalÄ±
X Ayarlar â†’ GÃ¼venlik â†’ Ä°ki faktÃ¶rlÃ¼ kimlik doÄŸrulama â†’ Kapat

# c) Åifrede Ã¶zel karakterler
"Åifre123!" â†’ elle yazÄ±n, copy-paste yapmayÄ±n

# d) Manuel kontrol
TarayÄ±cÄ±da x.com'a manuel giriÅŸ yapabilir misiniz?
```

#### **3. Tweet ToplanamÄ±yor**
```
âŒ Hata: "âŒ Ã–nce X'e giriÅŸ yapÄ±n"
```
**Ã‡Ã¶zÃ¼m:**
```bash
# GiriÅŸ durumunu kontrol edin
1. "GiriÅŸ Durumu" kutusunda âœ… mesajÄ± var mÄ±?
2. Manuel olarak x.com/home aÃ§Ä±lÄ±yor mu?
3. Uygulama penceresini minimize etmeyin
```

#### **4. Port Ã‡akÄ±ÅŸmasÄ±**
```
âŒ Hata: "Address already in use: 7864"
```
**Ã‡Ã¶zÃ¼m:**
```bash
# BaÅŸka port kullanÄ±n
python x_scraper.py  # Hata verecek
# x_scraper.py'de port 7864 â†’ 7865 deÄŸiÅŸtirin

# Veya Ã§alÄ±ÅŸan uygulamayÄ± kapatÄ±n
pkill -f "x_scraper.py"
```

#### **5. BoÅŸ CSV DosyasÄ±**
```
âŒ Sorun: CSV dosyasÄ± sadece header iÃ§eriyor
```
**Ã‡Ã¶zÃ¼m:**
```bash
# Daha fazla tweet sayÄ±sÄ± deneyin
Tweet SayÄ±sÄ±: 5 â†’ 20

# FarklÄ± zamanda deneyin
Ana sayfa timeline'Ä±nda tweet var mÄ± kontrol edin

# Debug mode
Terminal Ã§Ä±ktÄ±sÄ±nÄ± takip edin: "ğŸ” X tweet elementi bulundu"
```

### ğŸ› **Hata LoglarÄ±**

#### **Debug Modunu EtkinleÅŸtirme**
```python
# x_scraper.py'de logging seviyesini deÄŸiÅŸtirin
import logging
logging.basicConfig(level=logging.DEBUG)
```

#### **Terminal Ã‡Ä±ktÄ±sÄ±nÄ± Kaydetme**
```bash
# Ã‡alÄ±ÅŸtÄ±rÄ±rken loglarÄ± dosyaya kaydet
./start_x_scraper.sh 2>&1 | tee debug.log
```

#### **YaygÄ±n Hata KodlarÄ±**
| Hata Kodu | AÃ§Ä±klama | Ã‡Ã¶zÃ¼m |
|-----------|----------|-------|
| `TimeoutException` | Element bulunamadÄ± | Bekleme sÃ¼resini artÄ±rÄ±n |
| `NoSuchElementException` | Selector yanlÄ±ÅŸ | X arayÃ¼zÃ¼ deÄŸiÅŸmiÅŸ olabilir |
| `WebDriverException` | Chrome problemi | Chrome'u yeniden baÅŸlatÄ±n |
| `ConnectionRefusedError` | Port problemi | Portu deÄŸiÅŸtirin |

### ğŸš¨ **Acil Durum ProsedÃ¼rleri**

#### **Uygulama Dondu**
```bash
# 1. Ctrl+C ile durdurun
# 2. TÃ¼m Chrome process'lerini kapatÄ±n
pkill -f chrome
pkill -f chromium

# 3. Yeniden baÅŸlatÄ±n
./start_x_scraper.sh
```

#### **Sistem KaynaklarÄ± TÃ¼kendi**
```bash
# RAM kullanÄ±mÄ±nÄ± kontrol edin
free -h

# Chrome process'lerini kontrol edin
ps aux | grep chrome

# Gerekirse bilgisayarÄ± yeniden baÅŸlatÄ±n
sudo reboot
```

---

## ğŸ”„ GÃ¼ncellemeler ve BakÄ±m

### ğŸ“… **Rutin BakÄ±m**

#### **HaftalÄ±k Kontroller**
```bash
# Chrome gÃ¼ncellemesi
sudo apt update && sudo apt upgrade google-chrome-stable

# Python paketleri
source venv/bin/activate
pip list --outdated
```

#### **AylÄ±k Temizlik**
```bash
# Eski CSV dosyalarÄ±nÄ± arÅŸivle
mkdir -p archive/$(date +%Y-%m)
mv x_tweets_*.csv archive/$(date +%Y-%m)/

# Cache temizliÄŸi
rm -rf ~/.cache/selenium/
rm -rf /tmp/chrome*
```

### ğŸ”„ **GÃ¼ncelleme ProsedÃ¼rÃ¼**

#### **Manuel GÃ¼ncelleme**
```bash
# 1. Mevcut versiyonu yedekle
cp x_scraper.py x_scraper_backup.py

# 2. Yeni kodu indirin
# 3. AyarlarÄ±nÄ±zÄ± yeni dosyaya aktarÄ±n
# 4. Test edin
```

#### **Otomatik GÃ¼ncelleme** (Ä°leri seviye)
```bash
# GitHub'dan otomatik gÃ¼ncelleme scripti
cat > update_scraper.sh << 'SCRIPT'
#!/bin/bash
echo "ğŸ”„ X Scraper gÃ¼ncelleniyor..."
git pull origin main
pip install -r requirements.txt
echo "âœ… GÃ¼ncelleme tamamlandÄ±"
SCRIPT
```

---

## ğŸ“Š Performans Optimizasyonu

### âš¡ **HÄ±z Optimizasyonu**

#### **TarayÄ±cÄ± AyarlarÄ±**
```python
# Daha hÄ±zlÄ± loading iÃ§in x_scraper.py'de:
options.add_argument("--disable-images")
options.add_argument("--disable-plugins")  
options.add_argument("--disable-extensions")
options.add_argument("--no-first-run")
```

#### **Network Optimizasyonu**
```python
# Sadece gerekli kaynaklarÄ± yÃ¼kle
prefs = {"profile.managed_default_content_settings.images": 2}
options.add_experimental_option("prefs", prefs)
```

### ğŸ“ˆ **Kaynak YÃ¶netimi**

#### **RAM KullanÄ±mÄ±nÄ± Azaltma**
```python
# Tweet sayÄ±sÄ±nÄ± sÄ±nÄ±rla
max_tweets = 50  # 100 yerine

# Scroll sayÄ±sÄ±nÄ± azalt  
max_scrolls = 10  # 15 yerine
```

#### **CPU KullanÄ±mÄ±nÄ± Azaltma**
```python
# Daha uzun beklemeler
time.sleep(4)  # 3 yerine
```

---

## ğŸ“š API ve Entegrasyon

### ğŸ”Œ **Harici Entegrasyonlar**

#### **Google Sheets API**
```python
# Google Sheets'e otomatik upload iÃ§in:
import gspread
from oauth2client.service_account import ServiceAccountCredentials

# Credentials ayarla
scope = ["https://spreadsheets.google.com/feeds"]
creds = ServiceAccountCredentials.from_json_keyfile_name("creds.json", scope)
client = gspread.authorize(creds)

# Upload fonksiyonu
def upload_to_sheets(csv_file):
    sheet = client.open("X Tweets Analysis").sheet1
    with open(csv_file, 'r') as f:
        content = f.read()
    client.import_csv(sheet.id, content)
```

#### **Webhook Entegrasyonu**
```python
# Slack/Discord bildirim
import requests

def send_notification(message):
    webhook_url = "https://hooks.slack.com/..."
    requests.post(webhook_url, json={"text": message})

# Scraping tamamlandÄ±ÄŸÄ±nda bildir
send_notification(f"âœ… {len(tweets)} tweet toplandÄ±!")
```

### ğŸ“Š **Veri Analizi Ã–rnekleri**

#### **Pandas ile Analiz**
```python
import pandas as pd

# CSV'yi oku
df = pd.read_csv('x_tweets_20250729_143022.csv')

# Temel istatistikler
print(f"Toplam tweet: {len(df)}")
print(f"Ortalama beÄŸeni: {df['beÄŸeni'].mean():.0f}")
print(f"En popÃ¼ler tweet: {df.loc[df['beÄŸeni'].idxmax(), 'tweet']}")

# En aktif yazarlar
top_authors = df['yazar'].value_counts().head(10)
print("En aktif yazarlar:")
print(top_authors)
```

#### **Matplotlib ile Grafik**
```python
import matplotlib.pyplot as plt

# BeÄŸeni daÄŸÄ±lÄ±mÄ± histogramÄ±
plt.figure(figsize=(10, 6))
plt.hist(df['beÄŸeni'], bins=20, alpha=0.7)
plt.title('Tweet BeÄŸeni DaÄŸÄ±lÄ±mÄ±')
plt.xlabel('BeÄŸeni SayÄ±sÄ±')
plt.ylabel('Tweet SayÄ±sÄ±')
plt.savefig('begeni_dagilimi.png')
plt.show()
```

---

## ğŸ¤ KatkÄ±da Bulunma

### ğŸ’¡ **GeliÅŸtirme Fikirleri**

#### **Ã–zellik Talepleri**
- [ ] **Multi-account support**: Birden fazla hesap
- [ ] **Scheduled scraping**: ZamanlanmÄ±ÅŸ toplama
- [ ] **Real-time monitoring**: CanlÄ± takip
- [ ] **Advanced filters**: Hashtag, mention filtreleri
- [ ] **Export formats**: JSON, Excel, PDF export
- [ ] **Analytics dashboard**: Grafik ve analiz paneli

#### **Teknik Ä°yileÅŸtirmeler**
- [ ] **Docker support**: Containerized deployment
- [ ] **REST API**: HTTP API endpoint'leri
- [ ] **Database integration**: PostgreSQL/MySQL desteÄŸi
- [ ] **Proxy support**: Proxy sunucu desteÄŸi
- [ ] **Captcha solving**: Otomatik captcha Ã§Ã¶zÃ¼mÃ¼

### ğŸ”§ **GeliÅŸtirme OrtamÄ±**

#### **KatkÄ±da Bulunma AdÄ±mlarÄ±**
1. **Fork** edin
2. **Feature branch** oluÅŸturun: `git checkout -b yeni-ozellik`
3. **Commit** edin: `git commit -m "Yeni Ã¶zellik eklendi"`
4. **Push** edin: `git push origin yeni-ozellik`
5. **Pull Request** oluÅŸturun

#### **Code Style**
```python
# PEP 8 standardÄ±nÄ± takip edin
# Type hints kullanÄ±n
def scrape_tweets(max_tweets: int) -> List[Dict[str, Any]]:
    """Tweet'leri topla."""
    pass

# Docstring ekleyin
def login_x(username: str, password: str) -> bool:
    """
    X hesabÄ±na giriÅŸ yapar.
    
    Args:
        username: X kullanÄ±cÄ± adÄ±
        password: X ÅŸifresi
        
    Returns:
        GiriÅŸ baÅŸarÄ±lÄ±ysa True, aksi halde False
    """
```

### ğŸ› **Bug Raporu**

#### **Bug Raporu FormatÄ±**
```markdown
**Bug AÃ§Ä±klamasÄ±**
KÄ±sa ve net aÃ§Ä±klama

**HatayÄ± Tekrarlama AdÄ±mlarÄ±**
1. Bu adÄ±mÄ± izle
2. Bu butona tÄ±kla
3. Bu hatayÄ± gÃ¶r

**Beklenen DavranÄ±ÅŸ**
Ne olmasÄ±nÄ± bekliyordunuz

**Ekran GÃ¶rÃ¼ntÃ¼leri**
MÃ¼mkÃ¼nse screenshot ekleyin

**Sistem Bilgileri**
- OS: Ubuntu 22.04
- Python: 3.10.12
- Chrome: 126.0.6478.126
```

---

## ğŸ“„ Lisans

### ğŸ“œ **MIT LisansÄ±**

```
MIT License

Copyright (c) 2025 X Scraper

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
```

### âš–ï¸ **Yasal UyarÄ±lar**

#### **KullanÄ±m KoÅŸullarÄ±**# x_scrapper
